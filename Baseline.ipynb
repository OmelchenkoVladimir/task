{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "#mhq/train_punkt для русской токенизации (удалить, не понадобилась)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "import string\n",
    "from ast import literal_eval\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "#простейший baseline: используем натренированную модель для преобразования слов, усредняем для получения вектора для предложения;\n",
    "#далее тренируем логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = FastText.load(r'araneum/araneum_none_fasttextcbow_300_5_2018.model')\n",
    "size = 300 #model.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=195782, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_sent(tokens):\n",
    "    sentence = literal_eval(tokens)\n",
    "    res = np.zeros(size)\n",
    "    word_count = len(sentence)\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            res += model.wv[word]\n",
    "        except KeyError:\n",
    "            word_count -= 1 #некоторые 1-буквенные слова, слова вроде i, ii, iii.\n",
    "    if word_count <= 0: #если всех слов в предложении нет в словаре, удаляем предложение\n",
    "        return None\n",
    "    return res/word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train['avg_sent'] = train['tokens'].apply(avg_sent)\n",
    "test['avg_sent'] = test['tokens'].apply(avg_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.loc[train['avg_sent'].notnull()]\n",
    "test = test.loc[test['avg_sent'].notnull()] #здесь удаляем предложения (см. avg_sent)\n",
    "train = train.sample(frac = 1)\n",
    "test = test.sample(frac = 1) # случайно переставляем строки в датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = pd.DataFrame()\n",
    "test_features = pd.DataFrame()\n",
    "train_features['author'] = train.loc[:,'author'].map({'Гоголь' : 0, 'Гегель' : 1})\n",
    "test_features['author'] = test.loc[:,'author'].map({'Гоголь' : 0, 'Гегель' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_features = np.array(train['avg_sent'].tolist()) #массив массивов в 2d\n",
    "te_features = np.array(test['avg_sent'].tolist())\n",
    "for i in range(size):\n",
    "    train_features['f' + str(i)] = tr_features[:,i]\n",
    "    test_features['f' + str(i)] = te_features[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9299033786694566\n"
     ]
    }
   ],
   "source": [
    "#кросс-валидацию для baseline-модели не делал\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = LogisticRegression(random_state = 22)\n",
    "clf.fit(train_features.drop('author', axis = 1), train_features['author'])\n",
    "res = clf.predict(test_features.drop(['author'], axis = 1))\n",
    "print(accuracy_score(res, test_features['author']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7310</th>\n",
       "      <td>Все стояло, потупив глаза в землю.</td>\n",
       "      <td>['все', 'стояло', 'потупив', 'глаза', 'в', 'зе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7224</th>\n",
       "      <td>Зато… \\r\\n* * * — …хлебом в местах, где голод;...</td>\n",
       "      <td>['в', 'местах', 'где', 'голод', 'я', 'эту', 'ч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>— Нет, вы не так приняли дело: шипучего мы сам...</td>\n",
       "      <td>['нет', 'вы', 'не', 'так', 'приняли', 'дело', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Из предыдущей главы уже видно, в чем состоял г...</td>\n",
       "      <td>['из', 'предыдущей', 'главы', 'уже', 'видно', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5383</th>\n",
       "      <td>— С большим удовольствием.</td>\n",
       "      <td>['с', 'большим', 'удовольствием']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "7310                 Все стояло, потупив глаза в землю.   \n",
       "7224  Зато… \\r\\n* * * — …хлебом в местах, где голод;...   \n",
       "2793  — Нет, вы не так приняли дело: шипучего мы сам...   \n",
       "495   Из предыдущей главы уже видно, в чем состоял г...   \n",
       "5383                         — С большим удовольствием.   \n",
       "\n",
       "                                                 tokens  \n",
       "7310  ['все', 'стояло', 'потупив', 'глаза', 'в', 'зе...  \n",
       "7224  ['в', 'местах', 'где', 'голод', 'я', 'эту', 'ч...  \n",
       "2793  ['нет', 'вы', 'не', 'так', 'приняли', 'дело', ...  \n",
       "495   ['из', 'предыдущей', 'главы', 'уже', 'видно', ...  \n",
       "5383                  ['с', 'большим', 'удовольствием']  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.93 - на baseline решении\n",
    "#выведем предложения, которые это простейшее решение приписывает как Гоголю, так и Гегелю (abs(0.5 - proba) < x)\n",
    "x = 0.001\n",
    "proba = clf.predict_proba(test_features.drop(['author'], axis = 1))[:,0]\n",
    "pd.DataFrame([test['sentence'][abs(proba - 0.5) < x], test['tokens'][abs(proba - 0.5) < x]]).T"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
